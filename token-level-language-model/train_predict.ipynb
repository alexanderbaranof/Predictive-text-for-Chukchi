{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten,Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D,Dropout,LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Model\n",
    "\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "\n",
    "from keras.layers.embeddings import Embedding\n",
    "import tensorflow\n",
    "\n",
    "# from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 12736042683052316238,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23354508672\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 13921353494587940759\n",
       " physical_device_desc: \"device: 0, name: TITAN RTX, pci bus id: 0000:01:00.0, compute capability: 7.5\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_sentences = list()\n",
    "\n",
    "training_file = '../data/train.tsv'\n",
    "\n",
    "for i, line in enumerate(open(training_file).readlines()):\n",
    "    row = line.strip().split('\\t')\n",
    "    if len(row) > 1:\n",
    "        tokens = row[1].strip()\n",
    "\n",
    "        tokens = 'BEGIN' + tokens  + 'SPACE2'\n",
    "\n",
    "        tokens = tokens.replace(' ', ' SPACE ')\n",
    "\n",
    "        tokens = tokens.replace('>', ' ')\n",
    "\n",
    "        tokens = tokens.replace('BEGIN', 'BEGIN ')\n",
    "        tokens = tokens.replace('SPACE2', ' SPACE')\n",
    "\n",
    "        new_sentences.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BEGIN а маравкэва ра тэн SPACE таа ’ко йӈы н SPACE']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentences[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(new_sentences)):\n",
    "    new_sentences[i] = new_sentences[i].replace('  ', ' ')\n",
    "    new_sentences[i] = new_sentences[i].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['BEGIN',\n",
       "  'а',\n",
       "  'маравкэва',\n",
       "  'ра',\n",
       "  'тэн',\n",
       "  'SPACE',\n",
       "  'таа',\n",
       "  '’ко',\n",
       "  'йӈы',\n",
       "  'н',\n",
       "  'SPACE']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentences[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for sent in new_sentences:\n",
    "    if len(sent) > max_len:\n",
    "        max_len = len(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sentences = list()\n",
    "target_of_generated_sentences = list()\n",
    "for i, sent in enumerate(new_sentences):\n",
    "    for j in range(len(sent)-1):\n",
    "        if j == 0:\n",
    "            generated_sentences.append(sent[j])\n",
    "        else:\n",
    "            generated_sentences.append(sent[:j+1])\n",
    "        target_of_generated_sentences.append(sent[j+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(generated_sentences)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BEGIN', 'а']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_docs = tokenizer.texts_to_sequences(generated_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 15]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448152"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "target_of_generated_sentences = le.fit_transform(target_of_generated_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   4, 5123, 7883, ..., 6095, 5982,    0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_of_generated_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_labels = len(pd.unique(target_of_generated_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17405"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "different_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 131)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 131, 50)           870350    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 122, 1024)         513024    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 61, 1024)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 57, 512)           2621952   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 28, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 26, 256)           393472    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 34810)             53502970  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 17405)             605885455 \n",
      "=================================================================\n",
      "Total params: 663,787,223\n",
      "Trainable params: 663,787,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "219/219 [==============================] - 208s 931ms/step - loss: 6.7163 - accuracy: 0.2278\n",
      "Epoch 2/500\n",
      "219/219 [==============================] - 206s 943ms/step - loss: 4.4300 - accuracy: 0.3327\n",
      "Epoch 3/500\n",
      "219/219 [==============================] - 207s 943ms/step - loss: 3.9912 - accuracy: 0.3905\n",
      "Epoch 4/500\n",
      "219/219 [==============================] - 207s 944ms/step - loss: 3.6677 - accuracy: 0.4263\n",
      "Epoch 5/500\n",
      "219/219 [==============================] - 206s 942ms/step - loss: 3.4372 - accuracy: 0.4534\n",
      "Epoch 6/500\n",
      "219/219 [==============================] - 206s 941ms/step - loss: 3.2468 - accuracy: 0.4762\n",
      "Epoch 7/500\n",
      "219/219 [==============================] - 206s 941ms/step - loss: 3.0929 - accuracy: 0.4912\n",
      "Epoch 8/500\n",
      "219/219 [==============================] - 206s 941ms/step - loss: 2.9654 - accuracy: 0.5023\n",
      "Epoch 9/500\n",
      "219/219 [==============================] - 206s 941ms/step - loss: 2.8526 - accuracy: 0.5133\n",
      "Epoch 10/500\n",
      "219/219 [==============================] - 206s 941ms/step - loss: 2.7430 - accuracy: 0.5236\n",
      "Epoch 11/500\n",
      "219/219 [==============================] - 206s 941ms/step - loss: 2.6366 - accuracy: 0.5316\n",
      "Epoch 12/500\n",
      "219/219 [==============================] - 206s 941ms/step - loss: 2.5128 - accuracy: 0.5449\n",
      "Epoch 13/500\n",
      "219/219 [==============================] - 206s 941ms/step - loss: 2.4053 - accuracy: 0.5536\n",
      "Epoch 14/500\n",
      "219/219 [==============================] - 206s 941ms/step - loss: 2.2746 - accuracy: 0.5694\n",
      "Epoch 15/500\n",
      "219/219 [==============================] - 206s 941ms/step - loss: 2.1554 - accuracy: 0.5842\n",
      "Epoch 16/500\n",
      "219/219 [==============================] - 206s 941ms/step - loss: 2.0211 - accuracy: 0.6032\n",
      "Epoch 17/500\n",
      "219/219 [==============================] - 206s 941ms/step - loss: 1.9006 - accuracy: 0.6218\n",
      "Epoch 18/500\n",
      "219/219 [==============================] - 207s 945ms/step - loss: 1.7815 - accuracy: 0.6419\n",
      "Epoch 19/500\n",
      "219/219 [==============================] - 206s 940ms/step - loss: 1.6736 - accuracy: 0.6597\n",
      "Epoch 20/500\n",
      "219/219 [==============================] - 206s 939ms/step - loss: 1.5658 - accuracy: 0.6795\n",
      "Epoch 21/500\n",
      "219/219 [==============================] - 206s 939ms/step - loss: 1.4650 - accuracy: 0.6994\n",
      "Epoch 22/500\n",
      "219/219 [==============================] - 206s 939ms/step - loss: 1.3817 - accuracy: 0.7151\n",
      "Epoch 23/500\n",
      "219/219 [==============================] - 206s 939ms/step - loss: 1.3026 - accuracy: 0.7316\n",
      "Epoch 24/500\n",
      "219/219 [==============================] - 206s 943ms/step - loss: 1.2404 - accuracy: 0.7434\n",
      "Epoch 25/500\n",
      "219/219 [==============================] - 206s 939ms/step - loss: 1.1844 - accuracy: 0.7579\n",
      "Epoch 26/500\n",
      "219/219 [==============================] - 206s 938ms/step - loss: 1.1323 - accuracy: 0.7689\n",
      "Epoch 27/500\n",
      "219/219 [==============================] - 205s 938ms/step - loss: 1.0859 - accuracy: 0.7784\n",
      "Epoch 28/500\n",
      "219/219 [==============================] - 205s 938ms/step - loss: 1.0422 - accuracy: 0.7891\n",
      "Epoch 29/500\n",
      "219/219 [==============================] - 205s 938ms/step - loss: 1.0150 - accuracy: 0.7949\n",
      "Epoch 30/500\n",
      "219/219 [==============================] - 206s 940ms/step - loss: 0.9873 - accuracy: 0.8004\n",
      "Epoch 31/500\n",
      "219/219 [==============================] - 206s 941ms/step - loss: 0.9613 - accuracy: 0.8072\n",
      "Epoch 32/500\n",
      "219/219 [==============================] - 205s 938ms/step - loss: 0.9427 - accuracy: 0.8117\n",
      "Epoch 33/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.9123 - accuracy: 0.8176\n",
      "Epoch 34/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.8957 - accuracy: 0.8229\n",
      "Epoch 35/500\n",
      "219/219 [==============================] - 205s 938ms/step - loss: 0.8766 - accuracy: 0.8275\n",
      "Epoch 36/500\n",
      "219/219 [==============================] - 205s 938ms/step - loss: 0.8704 - accuracy: 0.8292\n",
      "Epoch 37/500\n",
      "219/219 [==============================] - 206s 942ms/step - loss: 0.8623 - accuracy: 0.8309\n",
      "Epoch 38/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.8520 - accuracy: 0.8325\n",
      "Epoch 39/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.8390 - accuracy: 0.8354\n",
      "Epoch 40/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.8356 - accuracy: 0.8362\n",
      "Epoch 41/500\n",
      "219/219 [==============================] - 205s 938ms/step - loss: 0.8290 - accuracy: 0.8367\n",
      "Epoch 42/500\n",
      "219/219 [==============================] - 205s 938ms/step - loss: 0.8286 - accuracy: 0.8385\n",
      "Epoch 43/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.8200 - accuracy: 0.8397\n",
      "Epoch 44/500\n",
      "219/219 [==============================] - 206s 939ms/step - loss: 0.8074 - accuracy: 0.8425\n",
      "Epoch 45/500\n",
      "219/219 [==============================] - 206s 939ms/step - loss: 0.8020 - accuracy: 0.8441\n",
      "Epoch 46/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7962 - accuracy: 0.8437\n",
      "Epoch 47/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7972 - accuracy: 0.8438\n",
      "Epoch 48/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7850 - accuracy: 0.8467\n",
      "Epoch 49/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7863 - accuracy: 0.8470\n",
      "Epoch 50/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7819 - accuracy: 0.8475\n",
      "Epoch 51/500\n",
      "219/219 [==============================] - 205s 935ms/step - loss: 0.7837 - accuracy: 0.8460\n",
      "Epoch 52/500\n",
      "219/219 [==============================] - 205s 934ms/step - loss: 0.7828 - accuracy: 0.8473\n",
      "Epoch 53/500\n",
      "219/219 [==============================] - 205s 935ms/step - loss: 0.7769 - accuracy: 0.8489\n",
      "Epoch 54/500\n",
      "219/219 [==============================] - 205s 935ms/step - loss: 0.7708 - accuracy: 0.8502\n",
      "Epoch 55/500\n",
      "219/219 [==============================] - 205s 935ms/step - loss: 0.7714 - accuracy: 0.8497\n",
      "Epoch 56/500\n",
      "219/219 [==============================] - 205s 934ms/step - loss: 0.7707 - accuracy: 0.8495\n",
      "Epoch 57/500\n",
      "219/219 [==============================] - 205s 934ms/step - loss: 0.7706 - accuracy: 0.8497\n",
      "Epoch 58/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7693 - accuracy: 0.8496\n",
      "Epoch 59/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7619 - accuracy: 0.8511\n",
      "Epoch 60/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7595 - accuracy: 0.8523\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7667 - accuracy: 0.8499\n",
      "Epoch 62/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7598 - accuracy: 0.8518\n",
      "Epoch 63/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7583 - accuracy: 0.8521\n",
      "Epoch 64/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7514 - accuracy: 0.8535\n",
      "Epoch 65/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7501 - accuracy: 0.8531\n",
      "Epoch 66/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7577 - accuracy: 0.8522\n",
      "Epoch 67/500\n",
      "219/219 [==============================] - 205s 935ms/step - loss: 0.7551 - accuracy: 0.8523\n",
      "Epoch 68/500\n",
      "219/219 [==============================] - 205s 935ms/step - loss: 0.7391 - accuracy: 0.8555\n",
      "Epoch 69/500\n",
      "219/219 [==============================] - 205s 935ms/step - loss: 0.7507 - accuracy: 0.8525\n",
      "Epoch 70/500\n",
      "219/219 [==============================] - 205s 935ms/step - loss: 0.7438 - accuracy: 0.8541\n",
      "Epoch 71/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7495 - accuracy: 0.8532\n",
      "Epoch 72/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7500 - accuracy: 0.8526\n",
      "Epoch 73/500\n",
      "219/219 [==============================] - 205s 934ms/step - loss: 0.7525 - accuracy: 0.8522\n",
      "Epoch 74/500\n",
      "219/219 [==============================] - 205s 935ms/step - loss: 0.7520 - accuracy: 0.8521\n",
      "Epoch 75/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7412 - accuracy: 0.8540\n",
      "Epoch 76/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7356 - accuracy: 0.8560\n",
      "Epoch 77/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7421 - accuracy: 0.8545\n",
      "Epoch 78/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7401 - accuracy: 0.8554\n",
      "Epoch 79/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7361 - accuracy: 0.8559\n",
      "Epoch 80/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7347 - accuracy: 0.8559\n",
      "Epoch 81/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7358 - accuracy: 0.8550\n",
      "Epoch 82/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7511 - accuracy: 0.8525\n",
      "Epoch 83/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7477 - accuracy: 0.8522\n",
      "Epoch 84/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7425 - accuracy: 0.8538\n",
      "Epoch 85/500\n",
      "219/219 [==============================] - 206s 939ms/step - loss: 0.7376 - accuracy: 0.8554\n",
      "Epoch 86/500\n",
      "219/219 [==============================] - 207s 946ms/step - loss: 0.7328 - accuracy: 0.8564\n",
      "Epoch 87/500\n",
      "219/219 [==============================] - 205s 938ms/step - loss: 0.7322 - accuracy: 0.8558\n",
      "Epoch 88/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7365 - accuracy: 0.8557\n",
      "Epoch 89/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7314 - accuracy: 0.8561\n",
      "Epoch 90/500\n",
      "219/219 [==============================] - 205s 938ms/step - loss: 0.7283 - accuracy: 0.8567\n",
      "Epoch 91/500\n",
      "219/219 [==============================] - 207s 944ms/step - loss: 0.7308 - accuracy: 0.8560\n",
      "Epoch 92/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7366 - accuracy: 0.8548\n",
      "Epoch 93/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7375 - accuracy: 0.8548\n",
      "Epoch 94/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7325 - accuracy: 0.8553\n",
      "Epoch 95/500\n",
      "219/219 [==============================] - 205s 938ms/step - loss: 0.7340 - accuracy: 0.8553\n",
      "Epoch 96/500\n",
      "219/219 [==============================] - 207s 944ms/step - loss: 0.7296 - accuracy: 0.8555\n",
      "Epoch 97/500\n",
      "219/219 [==============================] - 205s 938ms/step - loss: 0.7247 - accuracy: 0.8571\n",
      "Epoch 98/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7239 - accuracy: 0.8572\n",
      "Epoch 99/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7266 - accuracy: 0.8563\n",
      "Epoch 100/500\n",
      "219/219 [==============================] - 205s 938ms/step - loss: 0.7351 - accuracy: 0.8544\n",
      "Epoch 101/500\n",
      "219/219 [==============================] - 207s 943ms/step - loss: 0.7357 - accuracy: 0.8549\n",
      "Epoch 102/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7289 - accuracy: 0.8561\n",
      "Epoch 103/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7224 - accuracy: 0.8574\n",
      "Epoch 104/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7308 - accuracy: 0.8556\n",
      "Epoch 105/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7256 - accuracy: 0.8572\n",
      "Epoch 106/500\n",
      "219/219 [==============================] - 206s 942ms/step - loss: 0.7304 - accuracy: 0.8560\n",
      "Epoch 107/500\n",
      "219/219 [==============================] - 206s 938ms/step - loss: 0.7275 - accuracy: 0.8564\n",
      "Epoch 108/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7243 - accuracy: 0.8567\n",
      "Epoch 109/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7192 - accuracy: 0.8574\n",
      "Epoch 110/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7210 - accuracy: 0.8573\n",
      "Epoch 111/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7202 - accuracy: 0.8573\n",
      "Epoch 112/500\n",
      "219/219 [==============================] - 207s 943ms/step - loss: 0.7208 - accuracy: 0.8580\n",
      "Epoch 113/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7180 - accuracy: 0.8585\n",
      "Epoch 114/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7226 - accuracy: 0.8571\n",
      "Epoch 115/500\n",
      "219/219 [==============================] - 205s 935ms/step - loss: 0.7275 - accuracy: 0.8567\n",
      "Epoch 116/500\n",
      "219/219 [==============================] - 205s 936ms/step - loss: 0.7220 - accuracy: 0.8569\n",
      "Epoch 117/500\n",
      "219/219 [==============================] - 205s 937ms/step - loss: 0.7230 - accuracy: 0.8570\n",
      "Epoch 118/500\n",
      " 79/219 [=========>....................] - ETA: 2:12 - loss: 0.7156 - accuracy: 0.8593"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7117d75d7c7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_of_generated_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#with tensorflow.device('/device:GPU:0'):\n",
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 50, input_length=max_len)\n",
    "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(1024, 10, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Conv1D(512, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Conv1D(256, 3, activation='relu')(x)\n",
    "x = MaxPooling1D(4)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(different_labels*2, activation='relu')(x)\n",
    "preds = Dense(different_labels, activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(padded_docs, target_of_generated_sentences, epochs=500, verbose=1, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('cnn_tokens.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create morph parser from all data\n",
    "morph = dict()\n",
    "\n",
    "training_file = '../data/train.tsv'\n",
    "\n",
    "for i, line in enumerate(open(training_file).readlines()):\n",
    "    row = line.strip().split('\\t')\n",
    "    if len(row) > 1:\n",
    "        tokens = row[0].split(' ')\n",
    "        tokens_with_morph = row[1].split(' ')\n",
    "        for i in range(len(tokens)-1):\n",
    "            morph[tokens[i]] = tokens_with_morph[i]\n",
    "            \n",
    "\n",
    "training_file = '../data/dev.tsv'\n",
    "\n",
    "for i, line in enumerate(open(training_file).readlines()):\n",
    "    row = line.strip().split('\\t')\n",
    "    if len(row) > 1:\n",
    "        tokens = row[0].split(' ')\n",
    "        tokens_with_morph = row[1].split(' ')\n",
    "        for i in range(len(tokens)-1):\n",
    "            morph[tokens[i]] = tokens_with_morph[i]\n",
    "\n",
    "\n",
    "training_file = '../data/test/test.tsv'\n",
    "\n",
    "for i, line in enumerate(open(training_file).readlines()):\n",
    "    row = line.strip().split('\\t')\n",
    "    if len(row) > 1:\n",
    "        tokens = row[0].split(' ')\n",
    "        tokens_with_morph = row[1].split(' ')\n",
    "        for i in range(len(tokens)-1):\n",
    "            morph[tokens[i]] = tokens_with_morph[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30284"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "exist_text = ['BEGIN']\n",
    "exist_text = pad_sequences(tokenizer.texts_to_sequences([exist_text]), maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token = model.predict(exist_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token = np.argmax(next_token)\n",
    "next_token = le.inverse_transform([next_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ны'], dtype='<U21')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token = ''\n",
    "exist_text = ['BEGIN', 'вынэ']\n",
    "\n",
    "#tokenizer.texts_to_sequences(exist_text)\n",
    "cnt = 0\n",
    "while cnt < 10:\n",
    "    exist_text_array = pad_sequences(tokenizer.texts_to_sequences([exist_text]), maxlen=max_len, padding='post')\n",
    "    next_token = model.predict(exist_text_array)\n",
    "    next_token = np.argmax(next_token)\n",
    "    next_token = le.inverse_transform([next_token])\n",
    "    next_token = next_token[0]\n",
    "    exist_text += [next_token]\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(exist_text):\n",
    "    first_flag = False\n",
    "    if exist_text[0] == '#':\n",
    "        exist_text = ['BEGIN']\n",
    "        first_flag = True\n",
    "    else:\n",
    "        exist_text_save = copy.copy(exist_text)\n",
    "        exist_text = ['BEGIN']\n",
    "        for tok in exist_text_save:\n",
    "            morph_tokens = morph[tok].split('>')\n",
    "            for mrt in morph_tokens:\n",
    "                exist_text += [mrt]\n",
    "            exist_text += ['SPACE']\n",
    "    \n",
    "    next_token = ''\n",
    "    while next_token != 'SPACE':\n",
    "        exist_text_array = pad_sequences(tokenizer.texts_to_sequences([exist_text]), maxlen=max_len, padding='post')\n",
    "        next_token = model.predict(exist_text_array)\n",
    "        next_token = np.argmax(next_token)\n",
    "        next_token = le.inverse_transform([next_token])\n",
    "        next_token = next_token[0]\n",
    "        exist_text += [next_token]\n",
    "    \n",
    "    if first_flag:\n",
    "        index_1 = np.where(np.array(exist_text) == 'BEGIN')[0][-1]\n",
    "        index_2 = np.where(np.array(exist_text) == 'SPACE')[0][-1]\n",
    "    else:\n",
    "        index_1 = np.where(np.array(exist_text) == 'SPACE')[0][-2]\n",
    "        index_2 = np.where(np.array(exist_text) == 'SPACE')[0][-1]\n",
    "\n",
    "    next_word = ''.join(exist_text[index_1+1:index_2])\n",
    "    \n",
    "    return next_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('output_copy.tsv', 'w')\n",
    "\n",
    "n_tokens = 0\n",
    "hits = 0\n",
    "\n",
    "for line in tqdm(open('../data/dev.tsv').readlines()):\n",
    "    # Split into two columns\n",
    "    row = line.strip().split('\\t')\n",
    "    # Our tokens are in column one, split by space\n",
    "    tokens = row[0].split(' ')\n",
    "    # The test tokens are the beginning of sentence symbol + the list of tokens\n",
    "    tst_tokens = ['#'] + tokens\n",
    "    # Increment the number of tokens by the length of the list containing the tokens\n",
    "    n_tokens += len(tokens)\n",
    "\n",
    "    # This is our output\n",
    "    output = []\n",
    "\n",
    "    # For each of the tokens in the \"tst_tokens\" list (e.g. the list + the beginning of sentence symbol)\n",
    "    for i in range(len(tst_tokens)-1):\n",
    "        first = tst_tokens[i]  # First token in bigram\n",
    "        second = tst_tokens[i+1]  # Second token in bigram\n",
    "\n",
    "        if i == 0:\n",
    "            predicted_second = predict_next_word(tst_tokens[i])\n",
    "        else:\n",
    "            predicted_second = predict_next_word(tst_tokens[1:i+1])\n",
    "            \n",
    "        \n",
    "\n",
    "        if predicted_second == second:\n",
    "            # We add this whole token to the output\n",
    "            # e.g. a single click on a prediction\n",
    "\n",
    "            output.append(predicted_second)\n",
    "            #print(predicted_second)\n",
    "            #print(output)\n",
    "            # Increment the number of hits by 1\n",
    "            hits += 1\n",
    "        else:\n",
    "            # Otherwise we add each individual character to the output\n",
    "            # e.g. writing out each of the individual clicks\n",
    "            output += [c for c in second]\n",
    "\n",
    "        output.append('_')\n",
    "\n",
    "    \n",
    "    print('%s\\t%s' % (row[0], ' '.join(output)), file=f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "print(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 37897\r\n",
      "Tokens: 8788\r\n",
      "Clicks: 37752\r\n",
      "Clicks/Token: 4.295857988165681\r\n",
      "Clicks/Character: 0.9961738396179117\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ../evaluate.py ../data/dev.tsv ./output_copy.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1006/1006 [07:30<00:00,  2.24it/s]\n"
     ]
    }
   ],
   "source": [
    "f = open('output_copy_test.tsv', 'w')\n",
    "\n",
    "n_tokens = 0\n",
    "hits = 0\n",
    "\n",
    "for line in tqdm(open('../data/test/test.tsv').readlines()):\n",
    "    # Split into two columns\n",
    "    row = line.strip().split('\\t')\n",
    "    # Our tokens are in column one, split by space\n",
    "    tokens = row[0].split(' ')\n",
    "    # The test tokens are the beginning of sentence symbol + the list of tokens\n",
    "    tst_tokens = ['#'] + tokens\n",
    "    # Increment the number of tokens by the length of the list containing the tokens\n",
    "    n_tokens += len(tokens)\n",
    "\n",
    "    # This is our output\n",
    "    output = []\n",
    "\n",
    "    # For each of the tokens in the \"tst_tokens\" list (e.g. the list + the beginning of sentence symbol)\n",
    "    for i in range(len(tst_tokens)-1):\n",
    "        first = tst_tokens[i]  # First token in bigram\n",
    "        second = tst_tokens[i+1]  # Second token in bigram\n",
    "\n",
    "        if i == 0:\n",
    "            predicted_second = predict_next_word(tst_tokens[i])\n",
    "        else:\n",
    "            predicted_second = predict_next_word(tst_tokens[1:i+1])\n",
    "            \n",
    "        \n",
    "\n",
    "        if predicted_second == second:\n",
    "            # We add this whole token to the output\n",
    "            # e.g. a single click on a prediction\n",
    "\n",
    "            output.append(predicted_second)\n",
    "            #print(predicted_second)\n",
    "            #print(output)\n",
    "            # Increment the number of hits by 1\n",
    "            hits += 1\n",
    "        else:\n",
    "            # Otherwise we add each individual character to the output\n",
    "            # e.g. writing out each of the individual clicks\n",
    "            output += [c for c in second]\n",
    "\n",
    "        output.append('_')\n",
    "\n",
    "    \n",
    "    print('%s\\t%s' % (row[0], ' '.join(output)), file=f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 37927\r\n",
      "Tokens: 8374\r\n",
      "Clicks: 37911\r\n",
      "Clicks/Token: 4.527227131597803\r\n",
      "Clicks/Character: 0.9995781369472935\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ../evaluate.py ../data/test/test.tsv ./output_copy_test.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "7a3d88c904243d2c3f246166597f86d1c0a39f3d97496d1fe394945d0c6d436d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
