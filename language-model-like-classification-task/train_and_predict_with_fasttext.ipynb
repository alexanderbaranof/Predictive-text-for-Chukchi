{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "7a3d88c904243d2c3f246166597f86d1c0a39f3d97496d1fe394945d0c6d436d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten,Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D,Dropout,LSTM\n",
    "from keras.layers import Embedding\n",
    "\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = open('../data/dataset_for_char_rnn.txt').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['амаравкэваратэн', 'таа’койӈын'],\n",
       " ['йъйыӄык', 'ныӄэԓпэратӄэн', 'вытэчгытрыӄэргыԓьын', 'йыӈэттэт'],\n",
       " ['мыкыӈ', 'нывытрэтӄин', 'чеԓгатвытрыԓьо', 'ынӄорыым', 'вытэчгытрыԓьо']]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "for i in range(len(sentences)):\n",
    "    sentences[i] = sentences[i].strip().split(' ')\n",
    "sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = FastText(size=10, window=4, min_count=1)\n",
    "fasttext_model.build_vocab(sentences)\n",
    "fasttext_model.train(sentences, total_examples=len(sentences), epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0.89108765,  0.23914945,  0.7755417 ,  0.5666302 , -2.3441646 ,\n",
       "       -0.37617072, -1.2107517 ,  0.36574322,  1.1333429 ,  0.575741  ],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "fasttext_model['йъйыӄык']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_common = dict()\n",
    "\n",
    "training_file = '../data/train.tsv'\n",
    "\n",
    "for i, line in enumerate(open(training_file).readlines()):\n",
    "    row = line.strip().split('\\t')\n",
    "    tokens = row[0]\n",
    "    for id_tok, tok in enumerate(tokens.split(' ')):\n",
    "        if id_tok in result_dict_common:\n",
    "            result_dict_common[id_tok].append(tok)\n",
    "        else:\n",
    "            result_dict_common[id_tok] = list()\n",
    "            result_dict_common[id_tok].append(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/df_for_train_classifire.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   type             text          label\n",
       "0     2  амаравкэваратэн     таа’койӈын\n",
       "1     2          йъйыӄык  ныӄэԓпэратӄэн"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>амаравкэваратэн</td>\n      <td>таа’койӈын</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>йъйыӄык</td>\n      <td>ныӄэԓпэратӄэн</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2    26473\n",
       "3    20768\n",
       "4    15301\n",
       "5    10986\n",
       "6     7741\n",
       "Name: type, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df.type.value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "- 0s 518us/step - loss: 4.8360 - acc: 0.0145\n",
      "Epoch 4/10\n",
      "138/138 [==============================] - 0s 523us/step - loss: 4.8247 - acc: 0.0217\n",
      "Epoch 5/10\n",
      "138/138 [==============================] - 0s 497us/step - loss: 4.8250 - acc: 0.0217\n",
      "Epoch 6/10\n",
      "138/138 [==============================] - 0s 465us/step - loss: 4.8144 - acc: 0.0145\n",
      "Epoch 7/10\n",
      "138/138 [==============================] - 0s 492us/step - loss: 4.8214 - acc: 0.0145\n",
      "Epoch 8/10\n",
      "138/138 [==============================] - 0s 527us/step - loss: 4.7954 - acc: 0.0145\n",
      "Epoch 9/10\n",
      "138/138 [==============================] - 0s 522us/step - loss: 4.8099 - acc: 0.0217\n",
      "Epoch 10/10\n",
      "138/138 [==============================] - 0s 501us/step - loss: 4.7804 - acc: 0.0217\n",
      "Current type 17 All type 37\n",
      "Epoch 1/10\n",
      "99/99 [==============================] - 7s 69ms/step - loss: 4.5397 - acc: 0.0101\n",
      "Epoch 2/10\n",
      "99/99 [==============================] - 0s 630us/step - loss: 4.5221 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "99/99 [==============================] - 0s 651us/step - loss: 4.5118 - acc: 0.0101\n",
      "Epoch 4/10\n",
      "99/99 [==============================] - 0s 619us/step - loss: 4.5095 - acc: 0.0202\n",
      "Epoch 5/10\n",
      "99/99 [==============================] - 0s 620us/step - loss: 4.4998 - acc: 0.0101\n",
      "Epoch 6/10\n",
      "99/99 [==============================] - 0s 644us/step - loss: 4.5011 - acc: 0.0404\n",
      "Epoch 7/10\n",
      "99/99 [==============================] - 0s 652us/step - loss: 4.5033 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "99/99 [==============================] - 0s 652us/step - loss: 4.4888 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "99/99 [==============================] - 0s 639us/step - loss: 4.4930 - acc: 0.0505\n",
      "Epoch 10/10\n",
      "99/99 [==============================] - 0s 725us/step - loss: 4.5012 - acc: 0.0404\n",
      "Current type 18 All type 37\n",
      "Epoch 1/10\n",
      "74/74 [==============================] - 7s 92ms/step - loss: 4.3222 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - 0s 677us/step - loss: 4.3265 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - 0s 688us/step - loss: 4.2991 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - 0s 674us/step - loss: 4.2936 - acc: 0.0270\n",
      "Epoch 5/10\n",
      "74/74 [==============================] - 0s 682us/step - loss: 4.2586 - acc: 0.0135\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - 0s 641us/step - loss: 4.2875 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - 0s 661us/step - loss: 4.2522 - acc: 0.0270\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - 0s 672us/step - loss: 4.2669 - acc: 0.0135\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - 0s 680us/step - loss: 4.2553 - acc: 0.0135\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - 0s 679us/step - loss: 4.2522 - acc: 0.0000e+00\n",
      "Current type 19 All type 37\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 7s 128ms/step - loss: 3.9619 - acc: 0.0370\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 0s 673us/step - loss: 3.8919 - acc: 0.0370\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 0s 699us/step - loss: 3.8757 - acc: 0.0741\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 0s 681us/step - loss: 3.8796 - acc: 0.0741\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 0s 696us/step - loss: 3.8799 - acc: 0.0741\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 0s 705us/step - loss: 3.8610 - acc: 0.0741\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 0s 705us/step - loss: 3.8735 - acc: 0.0741\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 0s 703us/step - loss: 3.8683 - acc: 0.0741\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 0s 746us/step - loss: 3.8788 - acc: 0.0741\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 0s 696us/step - loss: 3.9063 - acc: 0.0741\n",
      "Current type 20 All type 37\n",
      "Epoch 1/10\n",
      "46/46 [==============================] - 7s 154ms/step - loss: 3.8323 - acc: 0.0435\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 0s 772us/step - loss: 3.8766 - acc: 0.0217\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 0s 825us/step - loss: 3.8493 - acc: 0.0217\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 0s 840us/step - loss: 3.8440 - acc: 0.0217\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 0s 840us/step - loss: 3.8212 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 0s 837us/step - loss: 3.8188 - acc: 0.0652\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 3.8258 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 0s 823us/step - loss: 3.8093 - acc: 0.0435\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 0s 884us/step - loss: 3.8310 - acc: 0.0435\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 0s 870us/step - loss: 3.7999 - acc: 0.0435\n",
      "Current type 21 All type 37\n",
      "Epoch 1/10\n",
      "34/34 [==============================] - 7s 212ms/step - loss: 3.5289 - acc: 0.0588\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3.5347 - acc: 0.0294\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3.5839 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3.5840 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3.5824 - acc: 0.0294\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3.5421 - acc: 0.0294\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3.5323 - acc: 0.0294\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3.5400 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3.5325 - acc: 0.0294\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 3.5438 - acc: 0.0294\n",
      "Current type 22 All type 37\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 7s 258ms/step - loss: 3.2875 - acc: 0.0357\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 0s 567us/step - loss: 3.3019 - acc: 0.0714\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 0s 669us/step - loss: 3.2277 - acc: 0.1071\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 0s 760us/step - loss: 3.2525 - acc: 0.0714\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 0s 721us/step - loss: 3.2662 - acc: 0.2143\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 0s 705us/step - loss: 3.2206 - acc: 0.1071\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 0s 702us/step - loss: 3.2564 - acc: 0.0714\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 0s 701us/step - loss: 3.2387 - acc: 0.1429\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 0s 740us/step - loss: 3.2901 - acc: 0.0714\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 0s 711us/step - loss: 3.2113 - acc: 0.0714\n",
      "Current type 23 All type 37\n",
      "Epoch 1/10\n",
      "21/21 [==============================] - 7s 350ms/step - loss: 3.1585 - acc: 0.0476\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 0s 821us/step - loss: 3.0285 - acc: 0.1429\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 0s 915us/step - loss: 3.2159 - acc: 0.0476\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 0s 991us/step - loss: 3.1138 - acc: 0.0476\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 0s 945us/step - loss: 3.0845 - acc: 0.0476\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 3.0567 - acc: 0.0952\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 0s 983us/step - loss: 3.0007 - acc: 0.1429\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 0s 987us/step - loss: 3.0827 - acc: 0.0952\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 0s 973us/step - loss: 3.0956 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 3.0280 - acc: 0.0952\n",
      "Current type 24 All type 37\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 7s 467ms/step - loss: 2.8775 - acc: 0.0625\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.8264 - acc: 0.1250\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.7947 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.8172 - acc: 0.0625\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.8499 - acc: 0.1250\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.8519 - acc: 0.0625\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.8569 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.7189 - acc: 0.1250\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.7840 - acc: 0.1250\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.7831 - acc: 0.1250\n",
      "Current type 25 All type 37\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 8s 860ms/step - loss: 2.4231 - acc: 0.1111\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3020 - acc: 0.1111\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2542 - acc: 0.1111\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2367 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1800 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.3248 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1270 - acc: 0.3333\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2080 - acc: 0.1111\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1682 - acc: 0.1111\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.0725 - acc: 0.3333\n",
      "Current type 26 All type 37\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 8s 1s/step - loss: 1.9672 - acc: 0.2857\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9098 - acc: 0.1429\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9048 - acc: 0.2857\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.8647 - acc: 0.2857\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.1696 - acc: 0.1429\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.8859 - acc: 0.2857\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0597 - acc: 0.1429\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9162 - acc: 0.2857\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9384 - acc: 0.1429\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9429 - acc: 0.1429\n",
      "Current type 27 All type 37\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.4248 - acc: 0.5000\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.4046 - acc: 0.2500\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.4624 - acc: 0.2500\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4031 - acc: 0.5000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.5256 - acc: 0.2500\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4795 - acc: 0.2500\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2248 - acc: 0.7500\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3894 - acc: 0.5000\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3789 - acc: 0.2500\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3843 - acc: 0.2500\n",
      "Current type 28 All type 37\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.3377 - acc: 0.2500\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.4807 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.5238 - acc: 0.2500\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.5648 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4342 - acc: 0.5000\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4797 - acc: 0.2500\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2018 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4044 - acc: 0.2500\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2994 - acc: 0.5000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3852 - acc: 0.0000e+00\n",
      "Current type 29 All type 37\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.6214 - acc: 0.5000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6162 - acc: 0.5000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6651 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7023 - acc: 0.5000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.8570 - acc: 0.5000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7094 - acc: 0.5000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5175 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4397 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6721 - acc: 0.5000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5315 - acc: 1.0000\n",
      "Current type 30 All type 37\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6343 - acc: 0.5000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6379 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.8594 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7303 - acc: 0.5000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5978 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7521 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5206 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4965 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6741 - acc: 0.5000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6770 - acc: 0.5000\n",
      "Current type 31 All type 37\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.7109 - acc: 0.5000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6414 - acc: 0.5000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7095 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7694 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9102 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7414 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6906 - acc: 0.5000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7542 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6796 - acc: 0.5000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6851 - acc: 0.5000\n",
      "Current type 32 All type 37\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6451 - acc: 0.5000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7271 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.0158 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7974 - acc: 0.5000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7906 - acc: 0.5000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6950 - acc: 0.5000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6672 - acc: 0.5000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5415 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7994 - acc: 0.5000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8330 - acc: 0.0000e+00\n",
      "Current type 33 All type 37\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.7196 - acc: 0.5000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5371 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8506 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7214 - acc: 0.5000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5944 - acc: 0.5000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6311 - acc: 0.5000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7958 - acc: 0.5000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7047 - acc: 0.5000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8934 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7646 - acc: 0.0000e+00\n",
      "Current type 34 All type 37\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.7197 - acc: 0.5000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6562 - acc: 0.5000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7034 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.6123 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.7027 - acc: 0.5000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6284 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8013 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5405 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.7743 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7043 - acc: 0.5000\n",
      "Current type 35 All type 37\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.8671 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3988 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5745 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6193 - acc: 0.5000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5421 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8085 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5357 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8316 - acc: 0.5000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7843 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6401 - acc: 0.5000\n",
      "Current type 36 All type 37\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 9s 5s/step - loss: 0.5230 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7823 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6862 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8159 - acc: 0.5000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6958 - acc: 0.5000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6315 - acc: 0.5000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.9075 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5375 - acc: 0.5000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6369 - acc: 0.5000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6063 - acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "result_dict = dict()\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df.text.tolist())\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "word_index = tokenizer.word_index\n",
    "EMBEDDING_DIM = 10\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        embedding_vector = fasttext_model[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n",
    "\n",
    "\n",
    "all_types = pd.unique(df.type).tolist()\n",
    "\n",
    "for id_t, t in enumerate(all_types):\n",
    "    print('Current type', id_t, 'All type', len(all_types))\n",
    "    tmp_df = df[df.type == t]\n",
    "    tmp_df = tmp_df.drop(['type'], axis=1)\n",
    "\n",
    "    result_dict[t] = dict()\n",
    "    result_dict[t]['le'] = LabelEncoder()\n",
    "    tmp_df['label'] = result_dict[t]['le'].fit_transform(tmp_df['label'])\n",
    "\n",
    "    labels_len = len(pd.unique(tmp_df['label']).tolist())\n",
    "\n",
    "    encoded_docs = tokenizer.texts_to_sequences(tmp_df.text.tolist())\n",
    "    \n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=t-1, padding='post')\n",
    "\n",
    "    labels = to_categorical(np.asarray(tmp_df['label'].tolist()))\n",
    "\n",
    "\n",
    "    # result_dict[t]['model'] = Sequential()\n",
    "    # result_dict[t]['model'].add(Embedding(result_dict[t]['vocab_size'], 10, input_length=t-1))\n",
    "    # result_dict[t]['model'].add(Activation('relu'))\n",
    "    # result_dict[t]['model'].add(Dropout(0.1))\n",
    "    # result_dict[t]['model'].add(Flatten())\n",
    "    # result_dict[t]['model'].add(Dense(30))\n",
    "    # result_dict[t]['model'].add(Activation('relu'))\n",
    "    # result_dict[t]['model'].add(Dense(labels_len))\n",
    "    # result_dict[t]['model'].add(Activation('softmax'))\n",
    "    # result_dict[t]['model'].compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # result_dict[t]['model'].fit(padded_docs, labels, epochs=5, verbose=1)\n",
    "\n",
    "    if id_t > 15:\n",
    "        epoh_n = 10\n",
    "    else:\n",
    "        epoh_n = 50\n",
    "\n",
    "    result_dict[t]['model'] = Sequential()\n",
    "    result_dict[t]['model'].add(Embedding(vocab_size, EMBEDDING_DIM, input_length=t-1, weights=[embedding_matrix], trainable=False))\n",
    "    result_dict[t]['model'].add(Dropout(0.2))\n",
    "    result_dict[t]['model'].add(LSTM(64))\n",
    "    result_dict[t]['model'].add(Dropout(0.2))\n",
    "    result_dict[t]['model'].add(Dense(labels_len, activation='softmax'))\n",
    "    result_dict[t]['model'].compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    result_dict[t]['model'].fit(padded_docs, labels, epochs=epoh_n, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1000/1000 [01:22<00:00, 12.09it/s]\n"
     ]
    }
   ],
   "source": [
    "f = open('output.tsv', 'w')\n",
    "\n",
    "n_tokens = 0\n",
    "hits = 0\n",
    "\n",
    "for line in tqdm(open('../data/dev.tsv').readlines()):\n",
    "    # Split into two columns\n",
    "    row = line.strip().split('\\t')\n",
    "    # Our tokens are in column one, split by space\n",
    "    tokens = row[0].split(' ')\n",
    "    # The test tokens are the beginning of sentence symbol + the list of tokens\n",
    "    tst_tokens = ['#'] + tokens\n",
    "    # Increment the number of tokens by the length of the list containing the tokens\n",
    "    n_tokens += len(tokens)\n",
    "\n",
    "    # This is our output\n",
    "    output = []\n",
    "\n",
    "    # For each of the tokens in the \"tst_tokens\" list (e.g. the list + the beginning of sentence symbol)\n",
    "    for i in range(len(tst_tokens)-1):\n",
    "        first = tst_tokens[i]  # First token in bigram\n",
    "        second = tst_tokens[i+1]  # Second token in bigram\n",
    "\n",
    "        if i == 0:\n",
    "            predicted_second = pd.Series(result_dict_common[0]).value_counts()[:1].index[0]\n",
    "        else:\n",
    "            exits_text = ' '.join(tst_tokens[1:i+1])\n",
    "            predicted_second = result_dict[i+1]['model'].predict(pad_sequences(tokenizer.texts_to_sequences([exits_text]), maxlen=i, padding='post'))\n",
    "            predicted_second = np.argmax(predicted_second)\n",
    "            predicted_second = result_dict[i+1]['le'].inverse_transform([predicted_second])\n",
    "            predicted_second = predicted_second[0]\n",
    "        \n",
    "\n",
    "        if predicted_second == second:\n",
    "            # We add this whole token to the output\n",
    "            # e.g. a single click on a prediction\n",
    "            output.append(predicted_second)\n",
    "            # Increment the number of hits by 1\n",
    "            hits += 1\n",
    "        else:\n",
    "            # Otherwise we add each individual character to the output\n",
    "            # e.g. writing out each of the individual clicks\n",
    "            output += [c for c in second]\n",
    "\n",
    "        output.append('_')\n",
    "\n",
    "    \n",
    "    print('%s\\t%s' % (row[0], ' '.join(output)), file=f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Characters: 37897\nTokens: 8788\nClicks: 37754\nClicks/Token: 4.2960855712335\nClicks/Character: 0.9962266142438716\n"
     ]
    }
   ],
   "source": [
    "!python3.7 ../evaluate.py ../data/dev.tsv ./output.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}